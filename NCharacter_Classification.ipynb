{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.feature, skimage.io\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pasta que contém o conjunto de dados já extraído.\n",
    "#Esta pasta contém as pastas A-Z e os arquivos NIST_Train_Upper.txt, NIST_Test_Upper.txt e NIST_Valid_Upper.txt\n",
    "NCharacter_dataset_folder = \"../exercicios/NCharacter_SD19_BMP/\"\n",
    "\n",
    "#Uma pasta onde as características extraídas são salvas.\n",
    "features_folder = 'features'\n",
    "\n",
    "#Classe que abstrai a divisão em zonas\n",
    "class Zonas(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #Função geradora que retorna uma zona de cada vez.\n",
    "    #Os argumentos são o número de linhas da imagem e o número de colunas da imagem.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        raise NotImplementedError\n",
    "\n",
    "#Classe que implementa a divisão em zonas retangulares.\n",
    "class ZonasRetangulares(Zonas):\n",
    "    \n",
    "    #Construtor que configura o zoneamento a ser feito: zonas_x zonas horizontais e zonas_y zonas verticais.\n",
    "    def __init__(self, zonas_x, zonas_y):\n",
    "        super(ZonasRetangulares, self).__init__()\n",
    "        self.zonas_x = zonas_x\n",
    "        self.zonas_y = zonas_y\n",
    "        \n",
    "    #Implementa a função geradora de zonas retangulares.\n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        cortes_x = np.floor(np.linspace(0, n_colunas, num=self.zonas_x+1)).astype(int)\n",
    "        cortes_y = np.floor(np.linspace(0, n_linhas, num=self.zonas_y+1)).astype(int)\n",
    "        #print (cortes_x)\n",
    "        #print (cortes_y)\n",
    "        for i in range(len(cortes_x)-1):\n",
    "            for j in range(len(cortes_y)-1):\n",
    "                yield(cortes_x[i], cortes_y[j], cortes_x[i+1], cortes_y[j+1],cortes_x[i] - cortes_x[i+1], cortes_y[i] - cortes_y[i+1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caraterísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma_cor(imagem):\n",
    "    #print('im', imagem.shape)\n",
    "    vals, counts = np.unique(imagem, return_counts=True)\n",
    "    o = vals.argsort()\n",
    "    vals = vals[o]\n",
    "    counts = counts[o]\n",
    "    if len(vals) < 2:\n",
    "        #imagem com apenas branco ou apenas preto\n",
    "        if vals[0] == 0:\n",
    "            return [counts[0], 0]\n",
    "        else:\n",
    "            return [0, counts[0]]\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraindo características de NIST_Train_Upper.txt\n",
      "extraindo características de NIST_Test_Upper.txt\n",
      "extraindo características de NIST_Valid_Upper.txt\n",
      "Fim da extração de características!\n"
     ]
    }
   ],
   "source": [
    "#Esta função apenas abre os arquivos com as listas de treino / teste e validação.\n",
    "#Retorna os caminhos para os arquivos, os rótulos e o nome dos arquivos sem o caminho.\n",
    "def parse_filelist(path, prefix=''):\n",
    "    with open(path, 'r') as f:\n",
    "        c = f.readlines()\n",
    "    caminhos = list(map(str.strip, c))\n",
    "    rotulos = [ i.split('/')[1].upper() for i in caminhos]\n",
    "    arquivos = [i.split('/')[-1] for i in caminhos]\n",
    "    p = zip(rotulos, arquivos)\n",
    "    caminhos = [ prefix + '/' + i[0] + '/' + i[1] for i in p]\n",
    "    \n",
    "    return list(zip(caminhos,rotulos, arquivos))\n",
    "\n",
    "#Esta é uma função que recebe o tipo de zoneamento a ser feito e as features que devem ser\n",
    "#extraídas de cada zona. Veja que essa função é chamada no \"for\" abaixo, que faz a extração das características\n",
    "#para cada uma das listas de imagens (treino, teste e validação)\n",
    "def extract_features(filelist, dataset_folder, zonas, features=[histograma_cor]):\n",
    "    instancias = parse_filelist(filelist, prefix=dataset_folder)\n",
    "    #Note que o MAP abaixo mapeia cada instância (imagem) à função que extrai as \n",
    "    #características (feature_extraction) abaixo.\n",
    "    features = list(map(feature_extraction, instancias, [zonas] * len(instancias), [features] * len(instancias)))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "#Essa função de extração das características de cada instância. zonas é uma instância de subclasse\n",
    "#de Zonas. Features é uma lista de funções que extraem características. Cada função da lista recebe uma matriz\n",
    "#que representa a imagem (que está na zona) e retorna o vetor de característica computado daquela característica. \n",
    "def feature_extraction(instancia, zonas, features):\n",
    "    caminho = instancia[0]\n",
    "    #print(instancia)\n",
    "    imagem = skimage.io.imread(caminho)\n",
    "    caracteristicas = np.array([])\n",
    "    #print(\"imagem.shape\",imagem.shape)\n",
    "    \n",
    "    res = []\n",
    "    for f in features:\n",
    "        for z in zonas.get_zonas(imagem.shape[1], imagem.shape[0]):\n",
    "            #print (\"%d:%d,%d:%d\" % (z[0], z[2], z[1], z[3]))\n",
    "            f_val = f(imagem[z[0]:z[2],z[1]:z[3]])\n",
    "            res.extend(f_val)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "#Realiza a extração das características!\n",
    "for i in [('NIST_Train_Upper.txt', 'train'), ('NIST_Test_Upper.txt', 'test'), ('NIST_Valid_Upper.txt', 'val')]:\n",
    "    print('extraindo características de %s' % (i[0]))\n",
    "    #note que esta linha extrai características de 4 zonas (2 zonas por linha e 2 por coluna). \n",
    "    #Neste exemplo apenas a característica histograma_cor é computada.\n",
    "    feats = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(2,2), features=[histograma_cor])\n",
    "    \n",
    "    #Extraia aqui outras características! Escolha outros zoneamentos! \n",
    "    #Exemplo: feats2 recebe as características de histograma de cor calculadas de 9 zonas \n",
    "    feats2 = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(3,3), features=[histograma_cor])\n",
    "    \n",
    "    \n",
    "    #Concatena feats e feats 2 em feats.\n",
    "    feats = np.concatenate((feats,feats2),axis=1)\n",
    "    \n",
    "    #np.save(open(features_folder + ('/%s_feats.pkl' % (i[1])), 'wb'), feats )\n",
    "    np.save(features_folder + ('/%s_feats.pkl' % (i[1])), feats)\n",
    "\n",
    "print('Fim da extração de características!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino e Teste com SVM e KNN (Sem validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37440 (37440, 26)\n",
      "11941 (11941, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score:  0.691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A      0.661     0.791     0.720       459\n",
      "          B      0.448     0.605     0.515       435\n",
      "          C      0.717     0.857     0.781       518\n",
      "          D      0.460     0.795     0.583       396\n",
      "          E      0.486     0.614     0.542       365\n",
      "          F      0.663     0.704     0.683       419\n",
      "          G      0.518     0.599     0.555       389\n",
      "          H      0.601     0.799     0.686       402\n",
      "          I      0.958     0.697     0.807       815\n",
      "          J      0.746     0.779     0.762       426\n",
      "          K      0.523     0.629     0.571       377\n",
      "          L      0.864     0.964     0.911       496\n",
      "          M      0.492     0.341     0.403       460\n",
      "          N      0.660     0.569     0.611       439\n",
      "          O      0.752     0.436     0.552       459\n",
      "          P      0.760     0.752     0.756       467\n",
      "          Q      0.680     0.540     0.602       452\n",
      "          R      0.576     0.298     0.393       446\n",
      "          S      0.757     0.694     0.725       445\n",
      "          T      0.868     0.951     0.907       469\n",
      "          U      0.707     0.825     0.761       458\n",
      "          V      0.777     0.780     0.778       482\n",
      "          W      0.799     0.661     0.724       475\n",
      "          X      0.912     0.727     0.809       472\n",
      "          Y      0.809     0.766     0.787       453\n",
      "          Z      0.799     0.704     0.749       467\n",
      "\n",
      "avg / total      0.707     0.691     0.689     11941\n",
      "\n",
      "SVM accuracy score:  0.700\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A      0.747     0.754     0.751       459\n",
      "          B      0.560     0.556     0.558       435\n",
      "          C      0.802     0.890     0.844       518\n",
      "          D      0.488     0.801     0.607       396\n",
      "          E      0.526     0.614     0.566       365\n",
      "          F      0.704     0.754     0.728       419\n",
      "          G      0.538     0.522     0.530       389\n",
      "          H      0.659     0.746     0.700       402\n",
      "          I      0.903     0.693     0.784       815\n",
      "          J      0.734     0.770     0.751       426\n",
      "          K      0.555     0.666     0.606       377\n",
      "          L      0.865     0.972     0.915       496\n",
      "          M      0.528     0.496     0.511       460\n",
      "          N      0.576     0.485     0.527       439\n",
      "          O      0.777     0.477     0.591       459\n",
      "          P      0.797     0.833     0.815       467\n",
      "          Q      0.657     0.524     0.583       452\n",
      "          R      0.639     0.408     0.498       446\n",
      "          S      0.797     0.697     0.743       445\n",
      "          T      0.916     0.959     0.937       469\n",
      "          U      0.632     0.852     0.726       458\n",
      "          V      0.787     0.780     0.783       482\n",
      "          W      0.572     0.592     0.582       475\n",
      "          X      0.791     0.761     0.775       472\n",
      "          Y      0.742     0.801     0.771       453\n",
      "          Z      0.793     0.690     0.738       467\n",
      "\n",
      "avg / total      0.708     0.700     0.697     11941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features = np.load(features_folder + '/train_feats.pkl.npy')\n",
    "train_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Train_Upper.txt')\n",
    "train_rotulos = [i[1] for i in train_rotulos]\n",
    "print (len(train_rotulos), train_features.shape)\n",
    "\n",
    "test_features = np.load(features_folder + '/test_feats.pkl.npy')\n",
    "test_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Test_Upper.txt')\n",
    "test_rotulos = [i[1] for i in test_rotulos]\n",
    "print (len(test_rotulos), test_features.shape)\n",
    "\n",
    "SS = StandardScaler()\n",
    "SS.fit(train_features)\n",
    "train_features = SS.transform(train_features)\n",
    "test_features = SS.transform(test_features)\n",
    "\n",
    "KNN = KNNC(n_neighbors=3)\n",
    "\n",
    "KNN.fit(train_features, train_rotulos)\n",
    "\n",
    "\n",
    "y_pred = KNN.predict(test_features)\n",
    "\n",
    "print('KNN accuracy score: ' , '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "#print(confusion_matrix(test_rotulos, y_pred))\n",
    "\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_features, train_rotulos)\n",
    "y_pred = clf.predict(test_features)\n",
    "\n",
    "print('SVM accuracy score: ', '{:.3f}'.format(accuracy_score(test_rotulos, y_pred)))\n",
    "#print(confusion_matrix(test_rotulos, y_pred))\n",
    "\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
