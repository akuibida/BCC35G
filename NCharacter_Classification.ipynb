{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.feature, skimage.io\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "NCharacter_dataset_folder = \"../exercicios/NCharacter_SD19_BMP/\"\n",
    "features_folder = 'features'\n",
    "\n",
    "class Zonas(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ZonasRetangulares(Zonas):\n",
    "    \n",
    "    def __init__(self, zonas_x, zonas_y):\n",
    "        super(ZonasRetangulares, self).__init__()\n",
    "        self.zonas_x = zonas_x\n",
    "        self.zonas_y = zonas_y\n",
    "        \n",
    "    \n",
    "    def get_zonas(self, n_linhas, n_colunas):\n",
    "        cortes_x = np.floor(np.linspace(0, n_colunas, num=self.zonas_x+1)).astype(int)\n",
    "        cortes_y = np.floor(np.linspace(0, n_linhas, num=self.zonas_y+1)).astype(int)\n",
    "        #print (cortes_x)\n",
    "        #print (cortes_y)\n",
    "        for i in range(len(cortes_x)-1):\n",
    "            for j in range(len(cortes_y)-1):\n",
    "                yield(cortes_x[i], cortes_y[j], cortes_x[i+1], cortes_y[j+1],cortes_x[i] - cortes_x[i+1], cortes_y[i] - cortes_y[i+1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma_cor(imagem):\n",
    "    #print('im', imagem.shape)\n",
    "    vals, counts = np.unique(imagem, return_counts=True)\n",
    "    o = vals.argsort()\n",
    "    vals = vals[o]\n",
    "    counts = counts[o]\n",
    "    if len(vals) < 2:\n",
    "        #imagem com apenas branco ou apenas preto\n",
    "        if vals[0] == 0:\n",
    "            return [counts[0], 0]\n",
    "        else:\n",
    "            return [0, counts[0]]\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filelist(path, prefix=''):\n",
    "    with open(path, 'r') as f:\n",
    "        c = f.readlines()\n",
    "    caminhos = list(map(str.strip, c))\n",
    "    rotulos = [ i.split('/')[1].upper() for i in caminhos]\n",
    "    arquivos = [i.split('/')[-1] for i in caminhos]\n",
    "    p = zip(rotulos, arquivos)\n",
    "    caminhos = [ prefix + '/' + i[0] + '/' + i[1] for i in p]\n",
    "    \n",
    "    return list(zip(caminhos,rotulos, arquivos))\n",
    "\n",
    "def extract_features(filelist, dataset_folder, zonas, features=[histograma_cor]):\n",
    "    instancias = parse_filelist(filelist, prefix=dataset_folder)\n",
    "    features = list(map(feature_extraction, instancias, [zonas] * len(instancias), [features] * len(instancias)))\n",
    "    \n",
    "    return np.array(features)\n",
    "    \n",
    "def feature_extraction(instancia, zonas, features):\n",
    "    caminho = instancia[0]\n",
    "    #print(instancia)\n",
    "    imagem = skimage.io.imread(caminho)\n",
    "    caracteristicas = np.array([])\n",
    "    #print(\"imagem.shape\",imagem.shape)\n",
    "    \n",
    "    res = []\n",
    "    for f in features:\n",
    "        for z in zonas.get_zonas(imagem.shape[1], imagem.shape[0]):\n",
    "            #print (\"%d:%d,%d:%d\" % (z[0], z[2], z[1], z[3]))\n",
    "            f_val = f(imagem[z[0]:z[2],z[1]:z[3]])\n",
    "            res.extend(f_val)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "for i in [('NIST_Train_Upper.txt', 'train'), ('NIST_Test_Upper.txt', 'test'), ('NIST_Valid_Upper.txt', 'val')]:\n",
    "    print('extraindo características de %s' % (i[0]))\n",
    "    feats = extract_features(NCharacter_dataset_folder + i[0], NCharacter_dataset_folder, ZonasRetangulares(2,2))\n",
    "    #np.save(open(features_folder + ('/%s_feats.pkl' % (i[1])), 'wb'), feats )\n",
    "    np.save(features_folder + ('/%s_feats.pkl' % (i[1])), feats)\n",
    "\n",
    "print('Fim da extração de características!')\n",
    "\n",
    "#parse_filelist(NCharacter_dataset_folder + 'NIST_Train_Upper.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load(features_folder + '/train_feats.pkl.npy')\n",
    "train_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Train_Upper.txt')\n",
    "train_rotulos = [i[1] for i in train_rotulos]\n",
    "print (len(train_rotulos), train_features.shape)\n",
    "\n",
    "KNN = KNNC(n_neighbors=3)\n",
    "\n",
    "KNN.fit(train_features, train_rotulos)\n",
    "\n",
    "test_features = np.load(features_folder + '/test_feats.pkl.npy')\n",
    "test_rotulos = parse_filelist(NCharacter_dataset_folder + 'NIST_Test_Upper.txt')\n",
    "test_rotulos = [i[1] for i in test_rotulos]\n",
    "print (len(test_rotulos), test_features.shape)\n",
    "\n",
    "y_pred = KNN.predict(test_features)\n",
    "\n",
    "print(accuracy_score(test_rotulos, y_pred))\n",
    "#print(confusion_matrix(test_rotulos, y_pred))\n",
    "\n",
    "print(classification_report(test_rotulos, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
